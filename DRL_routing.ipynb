{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DRL_routing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfqHP5ejtAkEIJuX3SW1au",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diogomgsimoes/DRL-Network-Path-Selection-For-Multimedia-Traffic-in-SDNs/blob/main/DRL_routing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIZ-xu66ZLk-"
      },
      "source": [
        "import networkx as nx\n",
        "from itertools import islice\n",
        "import copy\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from collections import deque\n",
        "import torch\n",
        "from matplotlib import pylab as plt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p8pAbxWW4vO"
      },
      "source": [
        "TOPOLOGY_FILE_NAME = 'topology.txt'\n",
        "NUMBER_OF_HOSTS = 8\n",
        "NUMBER_OF_PATHS = 5\n",
        "REWARD_SCALE = NUMBER_OF_HOSTS * NUMBER_OF_HOSTS * NUMBER_OF_PATHS"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqYU5z8PdNYv"
      },
      "source": [
        "class DRLEngine():\n",
        "    def __init__(self):\n",
        "        self.graph = nx.Graph()\n",
        "        self.link_bw_capacity = {}\n",
        "        self.current_link_bw = {}\n",
        "        self.hosts = {}\n",
        "        self.paths = {}\n",
        "        self.host_pairs = [('H1', 'H4'), ('H1', 'H5'), ('H2', 'H5'), ('H2', 'H8'), ('H3', 'H6'), ('H3', 'H7'), ('H4', 'H5'), ('H4', 'H8')]\n",
        "        self.requests_bw = [5, 10, 15, 20, 25, 30]\n",
        "\n",
        "        self.upload_topology()\n",
        "        self.build_graph()\n",
        "        self.calculate_paths()\n",
        "\n",
        "    def upload_topology(self):\n",
        "        with open(TOPOLOGY_FILE_NAME, 'r') as topo:\n",
        "            for row in topo.readlines():\n",
        "                row_data = row.split()\n",
        "                if 'H' in row_data[0]:\n",
        "                    self.hosts[row_data[0]] = row_data[1].replace(\"S\", \"\")\n",
        "                elif 'S' in row_data[0]:\n",
        "                    src_id = row_data[0].replace(\"S\", \"\")\n",
        "                    dst_id = row_data[1].replace(\"S\", \"\")\n",
        "                    self.link_bw_capacity[(src_id, dst_id)] = int(row_data[2])\n",
        "                    self.link_bw_capacity[(dst_id, src_id)] = int(row_data[2])\n",
        "\n",
        "        self.current_link_bw = copy.deepcopy(self.link_bw_capacity)\n",
        "\n",
        "    def build_graph(self):\n",
        "        with open(TOPOLOGY_FILE_NAME, 'r') as topo:\n",
        "            for line in topo.readlines():\n",
        "                nodes = line.split()[:2]\n",
        "                for node in nodes:\n",
        "                    if not self.graph.has_node(node):\n",
        "                        self.graph.add_node(node)\n",
        "                self.graph.add_edge(nodes[0], nodes[1])\n",
        "    \n",
        "    def k_shortest_paths(self, graph, source, target, k):\n",
        "        try: \n",
        "            calc = list(islice(nx.shortest_simple_paths(graph, source, target), k))\n",
        "        except nx.NetworkXNoPath:\n",
        "            calc = []\n",
        "            \n",
        "        return [path for path in calc]\n",
        "\n",
        "    def calculate_paths(self):\n",
        "        for src_host_id in range(1, NUMBER_OF_HOSTS+1):\n",
        "            src = \"H{}\".format(src_host_id)\n",
        "            for dst_host_id in range(1, NUMBER_OF_HOSTS+1):\n",
        "                dst = \"H{}\".format(dst_host_id)\n",
        "                self.paths[(src, dst)] = self.k_shortest_paths(self.graph, src, dst, NUMBER_OF_PATHS)\n",
        "                for path in self.paths[(src, dst)]:\n",
        "                    if len(path) != 0:\n",
        "                        for i in range(0, len(path)):\n",
        "                            if \"S\" in path[i]:\n",
        "                                path[i] = path[i].replace(\"S\", \"\")\n",
        "                                path[i] = int(path[i])\n",
        "\n",
        "    def make_reservation(self, path_id):\n",
        "        random.shuffle(self.host_pairs)\n",
        "        pair = self.host_pairs.pop(0)\n",
        "        path = self.paths[(pair[0], pair[1])][path_id][1:-1]\n",
        "        request_bw = self.requests_bw[random.randint(0, 5)]\n",
        "        # request_bw = 20\n",
        "\n",
        "        # print(\"Source-Destination:\", pair)\n",
        "        # print(\"Path:\", path_id)\n",
        "        # print(\"Request bw:\", request_bw)\n",
        "\n",
        "        for s1, s2 in zip(path[:-1], path[1:]):\n",
        "            if self.current_link_bw.get((str(s1), str(s2))):\n",
        "                self.current_link_bw[(str(s1), str(s2))] -= request_bw\n",
        "                if self.current_link_bw[(str(s1), str(s2))] == 0:\n",
        "                    self.current_link_bw[(str(s1), str(s2))] = 1\n",
        "            if self.current_link_bw.get((str(s2), str(s1))):\n",
        "                self.current_link_bw[(str(s2), str(s1))] -= request_bw\n",
        "                if self.current_link_bw[(str(s2), str(s1))] == 0:\n",
        "                    self.current_link_bw[(str(s2), str(s1))] = 1\n",
        "\n",
        "\n",
        "    def build_state(self):\n",
        "        state = np.empty((NUMBER_OF_HOSTS, NUMBER_OF_HOSTS, NUMBER_OF_PATHS, 1), dtype=object)\n",
        "        \n",
        "        for src in range(1, NUMBER_OF_HOSTS+1):\n",
        "            h_src = \"H{}\".format(src)\n",
        "            for dst in range(1, NUMBER_OF_HOSTS+1):\n",
        "                h_dst = \"H{}\".format(dst)\n",
        "                min_value = float('Inf')\n",
        "                cnt = 0\n",
        "                if len(self.paths[(h_src, h_dst)]) == 1:\n",
        "                    if self.paths[(h_src, h_dst)] == []:\n",
        "                        for idx in range(NUMBER_OF_PATHS):\n",
        "                            state[src-1, dst-1, idx] = 1\n",
        "                    else: \n",
        "                        state[src-1, dst-1, 0] = 100\n",
        "                        for idx in range(1, NUMBER_OF_PATHS):\n",
        "                            state[src-1, dst-1, idx] = 1\n",
        "                else:\n",
        "                    for path in self.paths[(h_src, h_dst)]:\n",
        "                        path = path[1:-1]\n",
        "                        for s1, s2 in zip(path[:-1], path[1:]):\n",
        "                            stats = self.current_link_bw.get((str(s1), str(s2)))\n",
        "                            if stats:\n",
        "                                if float(stats) < float(min_value):\n",
        "                                    min_value = self.current_link_bw[(str(s1), str(s2))]\n",
        "                    \n",
        "                        state[src-1, dst-1, cnt] = float(min_value)\n",
        "                        cnt += 1\n",
        "                        \n",
        "                    for idx in range(len(self.paths[(h_src, h_dst)]), NUMBER_OF_PATHS):\n",
        "                        state[src-1, dst-1, idx] = 1\n",
        "                    \n",
        "        return state\n",
        "\n",
        "    def reset(self):\n",
        "        # print(\"Bw:\", self.current_link_bw)\n",
        "        self.graph = nx.Graph()\n",
        "        self.host_pairs = [('H1', 'H4'), ('H1', 'H5'), ('H2', 'H5'), ('H2', 'H8'), ('H3', 'H6'), ('H3', 'H7'), ('H4', 'H5'), ('H4', 'H8')]\n",
        "        self.current_link_bw = copy.deepcopy(self.link_bw_capacity)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9dh0clKaaEH"
      },
      "source": [
        "class RoutingEnv(Env):\n",
        "    def __init__(self):\n",
        "        self.requests = 0\n",
        "        self.max_requests = random.randint(1, 8)\n",
        "        # self.max_requests = 8\n",
        "        self.done = False\n",
        "\n",
        "        self.engine = DRLEngine()\n",
        "\n",
        "        self.observation_space = Box(low=np.zeros((NUMBER_OF_HOSTS, NUMBER_OF_HOSTS, NUMBER_OF_PATHS, 1), dtype=np.float32), \\\n",
        "            high=np.full((NUMBER_OF_HOSTS, NUMBER_OF_HOSTS, NUMBER_OF_PATHS, 1), 100, dtype=np.float32), dtype=np.float32)\n",
        "        \n",
        "        self.action_space = Discrete(NUMBER_OF_PATHS)\n",
        "        self.state = np.full((NUMBER_OF_HOSTS, NUMBER_OF_HOSTS, NUMBER_OF_PATHS, 1), 100, dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.engine.make_reservation(action)\n",
        "        self.requests += 1\n",
        "        \n",
        "        reward = 0\n",
        "        self.state = self.engine.build_state()\n",
        "        # print(self.state)\n",
        "\n",
        "        for src in range(NUMBER_OF_HOSTS):\n",
        "            for dst in range(NUMBER_OF_HOSTS):\n",
        "                for path_number in range(NUMBER_OF_PATHS):\n",
        "                    bw = self.state[src, dst, path_number]\n",
        "                    if bw != None:\n",
        "                        if bw > 75:\n",
        "                            reward += 20\n",
        "                        elif bw > 50: \n",
        "                            reward += 10\n",
        "                        elif bw > 25: \n",
        "                            pass\n",
        "                        elif bw > 0: \n",
        "                            reward -= 10\n",
        "                        else:\n",
        "                            reward -= 50\n",
        "\n",
        "        if self.requests == self.max_requests:\n",
        "            self.done = True\n",
        "\n",
        "        # print(\"Action:\", action)\n",
        "        # print(\"Reward:\", reward)\n",
        "        # print(\"Requests:\", self.max_requests)\n",
        "        \n",
        "        return self.state, reward/REWARD_SCALE, self.done, {}\n",
        "\n",
        "    def render(self):\n",
        "        pass\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.state\n",
        "\n",
        "    def reset(self):\n",
        "        self.done = False\n",
        "        self.state = np.full((NUMBER_OF_HOSTS, NUMBER_OF_HOSTS, NUMBER_OF_PATHS, 1), 100, dtype=np.float32)\n",
        "        self.requests = 0\n",
        "        self.max_requests = random.randint(1, 8)\n",
        "        self.engine.reset()\n",
        "\n",
        "        return self.state"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS50a-C6koax"
      },
      "source": [
        "env = RoutingEnv()\n",
        "episodes = 10\n",
        "\n",
        "for episode in range(1, episodes + 1):\n",
        "    env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "\n",
        "    while not done:\n",
        "        n_state, reward, done, info = env.step(random.randint(0, 4))\n",
        "        score += reward\n",
        "\n",
        "    print('Episode: {}, Score: {}'.format(episode, score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzvBrbQCqtsq"
      },
      "source": [
        "env = RoutingEnv()\n",
        "\n",
        "# l1 = 320\n",
        "# l2 = 500\n",
        "# l3 = 800\n",
        "# l4 = 400\n",
        "# l5 = 200\n",
        "# l6 = 50\n",
        "# l7 = 5\n",
        "\n",
        "# model = torch.nn.Sequential(\n",
        "#     torch.nn.Linear(l1, l2),\n",
        "#     torch.nn.ReLU(),\n",
        "#     torch.nn.Linear(l2, l3),\n",
        "#     torch.nn.ReLU(),\n",
        "#     torch.nn.Linear(l3,l4),\n",
        "#     torch.nn.ReLU(),\n",
        "#     torch.nn.Linear(l4, l5),\n",
        "#     torch.nn.ReLU(),\n",
        "#     torch.nn.Linear(l5, l6),\n",
        "#     torch.nn.ReLU(),\n",
        "#     torch.nn.Linear(l6,l7)\n",
        "# )\n",
        "\n",
        "l1 = 320\n",
        "l2 = 160\n",
        "l3 = 80\n",
        "l4 = 5\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(l1, l2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(l2, l3),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(l3,l4)\n",
        ")\n",
        "\n",
        "model2 = copy.deepcopy(model)\n",
        "model2.load_state_dict(model.state_dict())\n",
        "\n",
        "gamma = 0.9\n",
        "epsilon = 0.3\n",
        "learning_rate = 1e-3\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n",
        "total_reward_list = []\n",
        "epochs = 5000\n",
        "mem_size = 512\n",
        "batch_size = 32\n",
        "sync_freq = 300\n",
        "replay = deque(maxlen=mem_size)\n",
        "\n",
        "for i in range(epochs):\n",
        "    print(\"Starting training, epoch:\", i)\n",
        "    cnt = 0\n",
        "    total_reward = 0\n",
        "    _state = env.get_state()\n",
        "    state1 = torch.flatten(torch.from_numpy(_state.astype(np.float32))).reshape(1,320)\n",
        "    done = False\n",
        "    env.reset()\n",
        "    \n",
        "    while not done: \n",
        "        print(\"Step:\", cnt+1)\n",
        "        cnt += 1\n",
        "        qval = model(state1) \n",
        "        qval_ = qval.data.numpy()\n",
        "        if (random.random() < epsilon):\n",
        "            action_ = np.random.randint(0,4)\n",
        "        else:\n",
        "            action_ = np.argmax(qval_)\n",
        "        \n",
        "        state, reward, done, _ = env.step(action_)\n",
        "        state2 = torch.flatten(torch.from_numpy(state.astype(np.float32))).reshape(1,320)\n",
        "        \n",
        "        exp = (state1, action_, reward, state2, done)\n",
        "        replay.append(exp)\n",
        "        state1 = state2\n",
        "        \n",
        "        if len(replay) > batch_size:\n",
        "            minibatch = random.sample(replay, batch_size)\n",
        "            state1_batch = torch.cat([s1 for (s1,a,r,s2,d) in minibatch])\n",
        "            action_batch = torch.Tensor([a for (s1,a,r,s2,d) in minibatch])\n",
        "            reward_batch = torch.Tensor([r for (s1,a,r,s2,d) in minibatch])\n",
        "            state2_batch = torch.cat([s2 for (s1,a,r,s2,d) in minibatch])\n",
        "            done_batch = torch.Tensor([d for (s1,a,r,s2,d) in minibatch])\n",
        "            Q1 = model(state1_batch) \n",
        "            with torch.no_grad():\n",
        "                Q2 = model2(state2_batch)\n",
        "            \n",
        "            Y = reward_batch + gamma * ((1-done_batch) * torch.max(Q2,dim=1)[0])\n",
        "            X = Q1.gather(dim=1,index=action_batch.long().unsqueeze(dim=1)).squeeze()\n",
        "            loss = loss_fn(X, Y.detach())\n",
        "            print(i, loss.item())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            losses.append(loss.item())\n",
        "            optimizer.step()\n",
        "            \n",
        "            if cnt % sync_freq == 0:\n",
        "                model2.load_state_dict(model.state_dict())\n",
        "        \n",
        "        total_reward += reward\n",
        "    \n",
        "    total_reward_list.append(total_reward)\n",
        "    print(\"Episode reward:\", total_reward)\n",
        "        \n",
        "    if epsilon > 0:\n",
        "        epsilon -= (1/epochs)\n",
        "        \n",
        "print(total_reward_list)\n",
        "   \n",
        "print('Plotting losses ...')     \n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Epochs\",fontsize=22)\n",
        "plt.ylabel(\"Loss\",fontsize=22)\n",
        "plt.savefig('avg_loss.png') \n",
        "\n",
        "print('Plotting rewards ...')     \n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(total_reward_list)\n",
        "plt.xlabel(\"Epochs\",fontsize=22)\n",
        "plt.ylabel(\"Return\",fontsize=22)\n",
        "plt.savefig('avg_return.png')\n",
        "\n",
        "sizes = [50, 100, 200]\n",
        "for size in sizes:\n",
        "    avg = []\n",
        "    for idx in range(0, len(total_reward_list), size):\n",
        "        avg += [sum(val for val in total_reward_list[idx:idx + size]) / size]\n",
        "\n",
        "    plt.figure(figsize=(10,7))\n",
        "    plt.plot(avg)\n",
        "    plt.xlabel(\"Epochs\",fontsize=22)\n",
        "    plt.ylabel(\"Return\",fontsize=22)\n",
        "    plt.savefig('avg_return_{}.png'.format(size))\n",
        "\n",
        "torch.save(model.state_dict(), 'dqn_model_exp_replay_target_network.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKEeUqX6FpcE"
      },
      "source": [
        "def test_model(model):\n",
        "    test_env = RoutingEnv()\n",
        "    _state = test_env.reset()\n",
        "    state = torch.flatten(torch.from_numpy(_state.astype(np.float32))).reshape(1,320)\n",
        "    done = False\n",
        "    rewards = []\n",
        "    while not done:\n",
        "        qval = model(state)\n",
        "        qval_ = qval.data.numpy()\n",
        "        action = np.argmax(qval_)\n",
        "        _state, reward, done, _ = test_env.step(action)\n",
        "        print(\"Action:\", action)\n",
        "        print(\"Done:\", done)\n",
        "        state = torch.flatten(torch.from_numpy(_state.astype(np.float32))).reshape(1,320)\n",
        "        rewards.append(reward)\n",
        "    print(\"Reward sum:\", sum(rewards))\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Us8g7PkKAWv"
      },
      "source": [
        "l1 = 320\n",
        "l2 = 160\n",
        "l3 = 80\n",
        "l4 = 5\n",
        "\n",
        "model_test = torch.nn.Sequential(\n",
        "    torch.nn.Linear(l1, l2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(l2, l3),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(l3,l4)\n",
        ")\n",
        "\n",
        "model_test.load_state_dict(torch.load(\"dqn_model_exp_replay_target_network.pt\"))\n",
        "test_model(model_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}